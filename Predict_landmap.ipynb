{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "from osgeo import gdal_array\n",
    "from osgeo import osr\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import image_utils as iu\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image, ImageEnhance\n",
    "from PIL import ImageFilter\n",
    "from keras.models import load_model\n",
    "from shutil import copy2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy_utils as nu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data'\n",
    "segmentation_path = os.path.join(data_path, 'segmentation')\n",
    "# Saved models\n",
    "saved_model_path = os.path.join(segmentation_path, 'saved-models')\n",
    "# Predictions path.\n",
    "prediction_path = os.path.join(segmentation_path, 'predictions')\n",
    "#\n",
    "original_path = os.path.join(segmentation_path, 'original')\n",
    "real_data_path = os.path.join(original_path, 'real')\n",
    "mask_data_path = os.path.join(original_path, 'mask')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(pred_mask):\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    return pred_mask[0]\n",
    "\n",
    "# Predicts the mask of an image.\n",
    "def predict_mask(unet, np_img, input_size):\n",
    "    # split image\n",
    "    image_width, image_height = input_size\n",
    "    np_img = nu.resize_np_image(np_img, (image_height, image_width))\n",
    "    np_img = np_img / 13029\n",
    "    pred = unet.predict(np.array([np_img]))\n",
    "    return np.asarray(create_mask(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_image(image, row_count, col_count, new_part_size):\n",
    "    # parts = []\n",
    "    width, height = image.size\n",
    "    left = 0\n",
    "    top = 0\n",
    "    right = width / col_count\n",
    "    bottom = height / row_count\n",
    "    rows = []\n",
    "    for r in range(row_count):\n",
    "        row = []\n",
    "        top = int(r * (height / row_count))\n",
    "        bottom = int(top + (height / row_count))\n",
    "        for c in range(col_count):\n",
    "            left = int(c * (width / col_count))\n",
    "            right = int(left + (width / col_count))\n",
    "            part = image.crop((left, top, right, bottom))\n",
    "            # part = part.resize(new_part_size)\n",
    "            # parts.append(part)\n",
    "            row.append(part)\n",
    "        rows.append(row)\n",
    "    return rows\n",
    "\n",
    "\n",
    "def crop_geoTiff(geoTiff, left, top, right, bottom, dtype='uint16'):\n",
    "    width = abs(right - left)\n",
    "    height = abs(top - bottom)\n",
    "    bands = []\n",
    "    for x in range(geoTiff.RasterCount):\n",
    "        band = geoTiff.GetRasterBand(x + 1).ReadAsArray(left, top,\n",
    "                                                        int(width), int(height))\n",
    "        bands.append(band)\n",
    "    output = np.zeros(\n",
    "        (int(height), int(width), geoTiff.RasterCount), dtype)\n",
    "    for x in range(len(bands)):\n",
    "        output[..., x] = bands[x]\n",
    "    return output\n",
    "\n",
    "def split_geoTiff_image_into_rows_and_columns(geoTiff, row_count, col_count):\n",
    "    # parts = []\n",
    "    width, height = geoTiff.RasterXSize, geoTiff.RasterYSize\n",
    "    left = 0\n",
    "    top = 0\n",
    "    right = width / col_count\n",
    "    bottom = height / row_count\n",
    "    rows = []\n",
    "    # bands = read_geoTiff_bands(geoTiff)\n",
    "    for r in range(row_count):\n",
    "        row = []\n",
    "        top = int(r * (height / row_count))\n",
    "        bottom = int(top + (height / row_count))\n",
    "        for c in range(col_count):\n",
    "            left = int(c * (width / col_count))\n",
    "            right = int(left + (width / col_count))\n",
    "            part = crop_geoTiff(geoTiff, left, top, right, bottom)\n",
    "            row.append(part)\n",
    "        rows.append(row)\n",
    "    return rows\n",
    "\n",
    "\n",
    "def split_image_into_rows(geoTiff, max_divided_image_size):\n",
    "    max_d_width, max_d_height = max_divided_image_size\n",
    "    image_width, image_height = geoTiff.RasterXSize, geoTiff.RasterYSize\n",
    "    row_count, col_count = int(\n",
    "        image_height / max_d_height), int(image_width / max_d_width)\n",
    "    rows = split_geoTiff_image_into_rows_and_columns(geoTiff, row_count, col_count)\n",
    "    return rows\n",
    "\n",
    "\n",
    "# empty_img = np.zeros([512, 1024], dtype=np.uint8)\n",
    "# empty_img.fill(0)\n",
    "\n",
    "def combine_predictions(rows, color_space='L'):\n",
    "    part_height, part_width = rows[0][0].shape\n",
    "    full_image_width, full_image_height = (\n",
    "        len(rows[0]) * part_width, len(rows) * part_height)\n",
    "    empty_img = np.zeros([full_image_height, full_image_width], dtype=np.uint8)\n",
    "    empty_img = Image.fromarray(empty_img).convert(color_space)\n",
    "    for x in range(len(rows)):\n",
    "        row = rows[x]\n",
    "        for i in range(len(row)):\n",
    "            image_part = row[i]\n",
    "            empty_img.paste(image_part, (i * part_width, x * part_height))\n",
    "    return empty_img\n",
    "\n",
    "def predict_image_parts(unet, rows,image_size):\n",
    "    new_rows = []\n",
    "    for row in rows:\n",
    "        new_row = []\n",
    "        for np_image in row:\n",
    "            print(np_image.shape)\n",
    "            mask = predict_mask(unet, np_image, image_size)  \n",
    "            new_row.append(mask)\n",
    "        new_rows.append(new_row)\n",
    "    return new_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-04 11:11:54.039106: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "mc_unet = load_model(os.path.join(\n",
    "    saved_model_path, 'multi_class_unet_model_2023-01-04 09-50-02.700072.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_im = read_geotiff_as_rgb_image(\n",
    "    'data/segmentation/PLANET IMAGES FROM WEBSITE/2015/Images_Dec15/L15-1009E-1056N.tif')\n",
    "im = real_im[0]\n",
    "# rows = split_image_into_rows(real_image, (512, 426))\n",
    "image_size = (320, 160)\n",
    "rows = split_image_into_rows(im, image_size)\n",
    "rows = predict_image_parts(unet, None, rows,  0.9, image_size)\n",
    "new_im = combine_predictions(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "PIL.Image.MAX_IMAGE_PIXELS = 392861216\n",
    "real_image = gdal.Open(os.path.join(\n",
    "    real_data_path, 'Sentinel_2_2017_cropped.tif'))\n",
    "mask_image = iu.read_image(os.path.join(\n",
    "    mask_data_path, 'Final_RLCM_Ghana_2017.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 160, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-04 11:31:38.915478: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "image_size = (160, 160)\n",
    "rows = split_image_into_rows(real_image, image_size)\n",
    "rows = predict_image_parts(mc_unet, rows, image_size)\n",
    "land_map = combine_predictions(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 6)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows[0][0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "ml-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "810de9b3cd2e024eccc92a1f9aa24c11a8d2eda5f7347a9fbc9c3402570ea0d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
